{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc236440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please compile source files before using functions CUDA extension.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/home/po/.ipython',\n",
       " '/home/po/TM5/s4g-release/inference/grasp_proposal/network_models',\n",
       " '/home/po/TM5/graspnetAPI/graspnetAPI',\n",
       " '/home/po/TM5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os, sys\n",
    "import sys\n",
    "from torchsummary import summary\n",
    "from pyquaternion import Quaternion\n",
    "import pytorch3d\n",
    "from pytorch3d import transforms\n",
    "# sys.path.append('/home/po/TM5/Pointnet_Pointnet2_pytorch')\n",
    "sys.path.append('/home/po/TM5/s4g-release/inference/grasp_proposal/network_models')\n",
    "sys.path.append('/home/po/TM5/graspnetAPI/graspnetAPI')\n",
    "sys.path.append('/home/po/TM5')\n",
    "from nn_utils.mlp import SharedMLP\n",
    "from pointnet2_utils.modules import PointNetSAModule, PointnetFPModule, PointNetSAAvgModule\n",
    "from nn_utils.functional import smooth_cross_entropy\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974438dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-12-10 19:55:41,954 - rigid_transformations - Failed to import geometry msgs in rigid_transformations.py.\n",
      "WARNING - 2021-12-10 19:55:41,955 - rigid_transformations - Failed to import ros dependencies in rigid_transforms.py\n",
      "WARNING - 2021-12-10 19:55:41,956 - rigid_transformations - autolab_core not installed as catkin package, RigidTransform ros methods will be unavailable\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/home/po/TM5/graspnet-baseline')\n",
    "import scipy.io as scio\n",
    "from dataset.graspnet_dataset1 import GraspNetDataset, collate_fn, load_grasp_labels\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2(nn.Module):\n",
    "    \"\"\"PointNet++ part segmentation with single-scale grouping\n",
    "\n",
    "    PointNetSA: PointNet Set Abstraction Layer\n",
    "    PointNetFP: PointNet Feature Propagation Layer\n",
    "\n",
    "    Args:\n",
    "        score_classes (int): the number of grasp score classes\n",
    "        num_centroids (tuple of int): the numbers of centroids to sample in each set abstraction module\n",
    "        radius (tuple of float): a tuple of radius to query neighbours in each set abstraction module\n",
    "        num_neighbours (tuple of int): the numbers of neighbours to query for each centroid\n",
    "        sa_channels (tuple of tuple of int): the numbers of channels within each set abstraction module\n",
    "        fp_channels (tuple of tuple of int): the numbers of channels for feature propagation (FP) module\n",
    "        num_fp_neighbours (tuple of int): the numbers of nearest neighbor used in FP\n",
    "        seg_channels (tuple of int): the numbers of channels in segmentation mlp\n",
    "        dropout_prob (float): the probability to dropout input features\n",
    "\n",
    "    References:\n",
    "        https://github.com/charlesq34/pointnet2/blob/master/models/pointnet2_part_seg.py\n",
    "\n",
    "    \"\"\"\n",
    "    _SA_MODULE = PointNetSAModule\n",
    "    _FP_MODULE = PointnetFPModule\n",
    "\n",
    "    def __init__(self,\n",
    "                 score_classes,\n",
    "                 num_centroids=(10240, 1024, 128, 0),\n",
    "                 radius=(0.2, 0.3, 0.4, -1.0),\n",
    "                 num_neighbours=(64, 64, 64, -1),\n",
    "                 sa_channels=((32, 32, 64), (64, 64, 128), (128, 128, 256), (256, 512, 1024)),\n",
    "                 fp_channels=((256, 256), (256, 128), (128, 128), (64, 64, 64)),\n",
    "                 num_fp_neighbours=(0, 3, 3, 3),\n",
    "                 seg_channels=(128,),\n",
    "                 num_removal_directions=5,\n",
    "                 dropout_prob=0.5):\n",
    "        super(PointNet2, self).__init__()\n",
    "\n",
    "        # Sanity check\n",
    "        num_sa_layers = len(num_centroids)\n",
    "        num_fp_layers = len(fp_channels)\n",
    "        assert len(radius) == num_sa_layers\n",
    "        assert len(num_neighbours) == num_sa_layers\n",
    "        assert len(sa_channels) == num_sa_layers\n",
    "        assert num_sa_layers == num_fp_layers\n",
    "        assert len(num_fp_neighbours) == num_fp_layers\n",
    "\n",
    "        # Set Abstraction Layers\n",
    "        feature_channels = 0\n",
    "        self.sa_modules = nn.ModuleList()\n",
    "        for ind in range(num_sa_layers):\n",
    "            sa_module = self._SA_MODULE(in_channels=feature_channels,\n",
    "                                        mlp_channels=sa_channels[ind],\n",
    "                                        num_centroids=num_centroids[ind],\n",
    "                                        radius=radius[ind],\n",
    "                                        num_neighbours=num_neighbours[ind],\n",
    "                                        use_xyz=True)\n",
    "            self.sa_modules.append(sa_module)\n",
    "            feature_channels = sa_channels[ind][-1]\n",
    "\n",
    "        inter_channels = [0]\n",
    "        inter_channels.extend([x[-1] for x in sa_channels])\n",
    "\n",
    "        # Feature Propagation Layers\n",
    "        self.fp_modules = nn.ModuleList()\n",
    "        feature_channels = inter_channels[-1]\n",
    "        for ind in range(num_fp_layers):\n",
    "            fp_module = self._FP_MODULE(in_channels=feature_channels + inter_channels[-2 - ind],\n",
    "                                        mlp_channels=fp_channels[ind],\n",
    "                                        num_neighbors=num_fp_neighbours[ind])\n",
    "            self.fp_modules.append(fp_module)\n",
    "            feature_channels = fp_channels[ind][-1]\n",
    "\n",
    "        # MLP\n",
    "        self.mlp_seg = SharedMLP(feature_channels, seg_channels, ndim=1, dropout_prob=dropout_prob)\n",
    "        self.seg_logit = nn.Conv1d(seg_channels[-1], 1, 1, bias=True)\n",
    "\n",
    "#         self.mlp_grasp_eval = SharedMLP(feature_channels + 28, seg_channels, ndim=2, dropout_prob=dropout_prob)\n",
    "#         self.grasp_eval_logit = nn.Conv2d(seg_channels[-1], 1, 1, bias=True)\n",
    "    \n",
    "        self.mlp_R = SharedMLP(feature_channels, seg_channels, ndim=1)\n",
    "        self.R_logit = nn.Conv1d(seg_channels[-1], 4, 1, bias=True)\n",
    "\n",
    "#         self.mlp_t = SharedMLP(feature_channels, seg_channels, ndim=1)\n",
    "#         self.t_logit = nn.Conv1d(seg_channels[-1], 3, 1, bias=True)\n",
    "\n",
    "#         self.mlp_movable = SharedMLP(feature_channels, seg_channels, ndim=1, dropout_prob=dropout_prob)\n",
    "#         self.movable_logit = nn.Sequential(\n",
    "#             nn.Conv1d(seg_channels[-1], num_removal_directions, 1, bias=True),\n",
    "#             nn.Sigmoid())\n",
    "\n",
    "        self.init_weights()\n",
    "    def forward(self, data_batch):\n",
    "        points = data_batch[\"point_clouds\"]\n",
    "\n",
    "        xyz = points\n",
    "        feature = None\n",
    "\n",
    "        # save intermediate results\n",
    "        inter_xyz = [xyz]\n",
    "        inter_feature = [feature]\n",
    "\n",
    "        # Set Abstraction Layers\n",
    "        for sa_module in self.sa_modules:\n",
    "            xyz, feature = sa_module(xyz, feature)\n",
    "            inter_xyz.append(xyz)\n",
    "            inter_feature.append(feature)\n",
    "\n",
    "        # Feature Propagation Layers\n",
    "        sparse_xyz = xyz\n",
    "        sparse_feature = feature\n",
    "        for fp_ind, fp_module in enumerate(self.fp_modules):\n",
    "            dense_xyz = inter_xyz[-2 - fp_ind]\n",
    "            dense_feature = inter_feature[-2 - fp_ind]\n",
    "            fp_feature = fp_module(dense_xyz, sparse_xyz, dense_feature, sparse_feature)\n",
    "            sparse_xyz = dense_xyz\n",
    "            sparse_feature = fp_feature\n",
    "\n",
    "        # MLP\n",
    "        x = self.mlp_seg(sparse_feature)\n",
    "        logits = self.seg_logit(x)\n",
    "        \n",
    "              \n",
    "        \n",
    "        \n",
    "        R = self.mlp_R(sparse_feature)\n",
    "        R = self.R_logit(R)\n",
    "        R = F.normalize(R, dim=1)\n",
    "        # R = toRotMatrix(R)\n",
    "        # R = euler2RotMatrix(R)\n",
    "\n",
    "#         t = self.mlp_t(sparse_feature)\n",
    "#         t = self.t_logit(t)\n",
    "        \n",
    "#         local_search_frame = torch.cat([R, t], dim=1).unsqueeze(-1)\n",
    "#         local_search_frame = local_search_frame.repeat(1, 4, 1, 1)\n",
    "#         sparse_feature = sparse_feature.unsqueeze(-1)\n",
    "#         valid_feature = torch.cat([sparse_feature, local_search_frame], dim=1)\n",
    "#         local_search_logit = self.grasp_eval_logit(self.mlp_grasp_eval(valid_feature))\n",
    "        # t = points + t\n",
    "        \n",
    "#         mov = self.mlp_movable(sparse_feature)\n",
    "#         mov = self.movable_logit(mov)  # (B, 5, N)\n",
    "        \n",
    "            \n",
    "        preds = {\n",
    "#                 \"score\": logits,\n",
    "#                 \"score_pred\": local_search_logit,\n",
    "                \"score_pred\": logits,\n",
    "                 \"q_pred\": R,\n",
    "#                  \"xyz_pred\": t,\n",
    "#                  \"movable_logits\": mov,\n",
    "                 }\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def init_weights(self):\n",
    "        # nn_utils.init.zeros_(self.t_logit.weight)\n",
    "        # nn_utils.init.zeros_(self.t_logit.bias)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1,4,5->20000)\n",
    "A = torch.tensor([[[1., 2., 3., 4., 5.],\n",
    "         [1., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.]]])\n",
    "B = torch.tensor([[[2., 2., 3., 4., 5.],\n",
    "         [5., 2., 3., 4., 5.],\n",
    "         [4., 2., 3., 4., 5.],\n",
    "         [3., 2., 3., 4., 5.]]])\n",
    "C = B-A\n",
    "C\n",
    "F.normalize(C**2,dim=1)\n",
    "# (C**2).mean(1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input = torch.tensor([[[1., 2., 3., 4., 5.],\n",
    "         [1., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.]]])\n",
    "target = torch.tensor([[[3.,4., 3., 4., 5.],\n",
    "         [3., 4., 3., 4., 5.],\n",
    "         [3., 3., 3., 4., 5.],\n",
    "         [3., 3., 3., 4., 5.]]])\n",
    "# output.backward()\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AA = tmp_dic['score_label'].permute(0,2,1)\n",
    "# AA.squeeze(0).shape\n",
    "# data_batch = {\n",
    "#         \"point_clouds\": tmp_dic[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "# #         \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "#         \"q_label\": tmp_dic[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "# #         \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "#             \"score_label\": tmp_dic[\"score_label\"].permute(0,2,1).float().cuda(),\n",
    "#         }\n",
    "G = torch.ones(2,20000,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36dd20",
   "metadata": {},
   "source": [
    "R = torch.ones(1,4,20000)\n",
    "t = torch.ones(1,3,20000)\n",
    "sparse_feature = torch.ones(1,256,20000)\n",
    "local_search_frame = torch.cat([R, t], dim=1).unsqueeze(-1)\n",
    "local_search_frame.shape\n",
    "local_search_frame = local_search_frame.repeat(1, 4, 1, 1)\n",
    "sparse_feature = sparse_feature.unsqueeze(-1)\n",
    "valid_feature = torch.cat([sparse_feature, local_search_frame], dim=1)\n",
    "valid_feature.shape\n",
    "# # model.mlp_grasp_eval(valid_feature.cuda())\n",
    "local_search_logit = model.grasp_eval_logit(model.mlp_grasp_eval(valid_feature))\n",
    "local_search_logit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b532fdb",
   "metadata": {},
   "source": [
    "R = torch.tensor([[[1, 0.5000, 0.5000, 0.5000, 0.5000],\n",
    "         [1, 0.5000, 0.5000, 0.5000, 0.5000],\n",
    "         [2, 0.5000, 0.5000, 0.5000, 0.5000],\n",
    "         [2, 0.5000, 0.5000, 0.5000, 0.5000]]])\n",
    "print(R.shape)\n",
    "R = torch.nn.functional.normalize(R, dim=1)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe958cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2Loss(nn.Module):\n",
    "    def __init__(self, label_smoothing=0, neg_weight=0.1):\n",
    "        super(PointNet2Loss, self).__init__()\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.neg_weight = neg_weight\n",
    "        self.loss1 = nn.L1Loss()\n",
    "        self.loss2 = nn.MSELoss()\n",
    "    def forward(self, preds, labels):\n",
    "        \n",
    "        score_label = labels[\"score_label\"].permute(0,2,1)#.unsqueeze(-1) #(1,20000,1)\n",
    "        score_pred = preds[\"score_pred\"].permute(0,2,1)  #(1,20000,1)\n",
    "        score_loss = torch.pow((score_pred - score_label), 2)  #torch.Size([1, 20000, 4])\n",
    "\n",
    "        values_score , indice_score = torch.topk(score_loss, 400, dim=1, largest=True, sorted=True, out=None)\n",
    "        loss1 = torch.mean(values_score)\n",
    "\n",
    "        q_label = labels[\"q_label\"].permute(0,2,1)#(1,20000,4)\n",
    "        q_pred = preds[\"q_pred\"].permute(0,2,1) #(1,20000,4)\n",
    "        unit_q = torch.cat((torch.ones(1,20000,1),torch.zeros(1,20000,3)),dim=2) #torch.Size([1, 20000, 4])\n",
    "        q_label_inverse = pytorch3d.transforms.quaternion_invert(q_label) #torch.Size([1, 20000, 4])\n",
    "        Result1 = pytorch3d.transforms.quaternion_multiply(a =q_pred,b=q_label_inverse)#torch.Size([1, 20000, 4])\n",
    "        Result2 = pytorch3d.transforms.standardize_quaternion(Result1)#torch.Size([1, 20000, 4])\n",
    "        Result3 = Result2 - unit_q#torch.Size([1, 20000, 4])\n",
    "        q_loss = Result3.norm(dim=2,keepdim=True)#torch.Size([1, 20000, 1])\n",
    "        values_q, indice_q = torch.topk(q_loss, 400, dim=1, largest=True, sorted=True, out=None) #values_q:torch.Size([1, 400, 1])\n",
    "        loss2 = torch.mean(values_q)\n",
    "\n",
    "#         q_loss = values.sum()\n",
    "\n",
    "        loss_dict = {\n",
    "                    \"score_loss\": loss1,\n",
    "                     \"q_loss\": loss2,\n",
    "#                      \"xyz_loss\": xyz_loss,\n",
    "                     }\n",
    "\n",
    "        return loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d00912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2Metric(nn.Module):\n",
    "    def forward(self, preds, labels):\n",
    "        scene_score_logits = preds[\"scene_score_logits\"]  # (B, C, N2)\n",
    "        score_classes = scene_score_logits.shape[1]\n",
    "\n",
    "        scene_score_labels = labels[\"scene_score_labels\"]  # (B, N)\n",
    "\n",
    "        selected_preds = scene_score_logits.argmax(1).view(-1)\n",
    "        scene_score_labels = scene_score_labels.view(-1)\n",
    "\n",
    "        cls_acc = selected_preds.eq(scene_score_labels).float()\n",
    "\n",
    "        movable_logits = preds[\"movable_logits\"]\n",
    "        movable_labels = labels[\"scene_movable_labels\"]\n",
    "        movable_preds = (movable_logits > 0.5).view(-1).int()\n",
    "        movable_labels = movable_labels.view(-1).int()\n",
    "        mov_acc = movable_preds.eq(movable_labels).float()\n",
    "\n",
    "        gt_frame_R = labels[\"best_frame_R\"]\n",
    "        batch_size, _, num_frame_points = gt_frame_R.shape\n",
    "        pred_frame_R = preds[\"frame_R\"][:, :, :num_frame_points]\n",
    "        gt_frame_R = gt_frame_R.transpose(1, 2).contiguous().view(batch_size * num_frame_points, 3, 3)\n",
    "        gt_frame_R_inv = gt_frame_R.clone()\n",
    "        gt_frame_R_inv[:, :, 1:] = -gt_frame_R_inv[:, :, 1:]\n",
    "        pred_frame_R = pred_frame_R.transpose(1, 2).contiguous().view(batch_size * num_frame_points, 3, 3)\n",
    "        M = torch.bmm(gt_frame_R, pred_frame_R.transpose(1, 2))\n",
    "        angle = torch.acos(torch.clamp((M[:, 0, 0] + M[:, 1, 1] + M[:, 2, 2] - 1.0) / 2.0, -1.0, 1.0))\n",
    "        M_inv = torch.bmm(gt_frame_R_inv, pred_frame_R.transpose(1, 2))\n",
    "        angle_inv = torch.acos(torch.clamp((M_inv[:, 0, 0] + M_inv[:, 1, 1] + M_inv[:, 2, 2] - 1.0) / 2.0, -1.0, 1.0))\n",
    "\n",
    "        angle_min = torch.stack([angle, angle_inv], dim=1).min(1)[0]\n",
    "        gt_scene_score = labels[\"scene_score\"][:, :num_frame_points].contiguous().view(-1)\n",
    "        angle_min = (gt_scene_score * angle_min).mean()\n",
    "\n",
    "        gt_frame_t = labels[\"best_frame_t\"].view(-1)\n",
    "        pred_frame_t = preds[\"frame_t\"][:, :, :num_frame_points]\n",
    "        pred_frame_t = torch.argmax(pred_frame_t, dim=1).view(-1)\n",
    "        t_acc = pred_frame_t.eq(gt_frame_t).float()\n",
    "\n",
    "        # t_err = torch.mean(torch.sqrt(((gt_frame_t - pred_frame_t) ** 2).sum(1)))\n",
    "\n",
    "        return {\"cls_acc\": cls_acc,\n",
    "                \"mov_acc\": mov_acc,\n",
    "                \"R_err\": angle_min,\n",
    "                \"t_acc\": t_acc,\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb35f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_pointnet2_cls(cfg):\n",
    "def build_model(cfg):\n",
    "    net = PointNet2(\n",
    "        score_classes=cfg.DATA.SCORE_CLASSES,\n",
    "        num_centroids=cfg.MODEL.PN2.NUM_CENTROIDS,\n",
    "        radius=cfg.MODEL.PN2.RADIUS,\n",
    "        num_neighbours=cfg.MODEL.PN2.NUM_NEIGHBOURS,\n",
    "        sa_channels=cfg.MODEL.PN2.SA_CHANNELS,\n",
    "        fp_channels=cfg.MODEL.PN2.FP_CHANNELS,\n",
    "        num_fp_neighbours=cfg.MODEL.PN2.NUM_FP_NEIGHBOURS,\n",
    "        seg_channels=cfg.MODEL.PN2.SEG_CHANNELS,\n",
    "        num_removal_directions=cfg.DATA.NUM_REMOVAL_DIRECTIONS,\n",
    "        dropout_prob=cfg.MODEL.PN2.DROPOUT_PROB,\n",
    "    )\n",
    "\n",
    "    loss_func = PointNet2Loss(\n",
    "        label_smoothing=cfg.MODEL.PN2.LABEL_SMOOTHING,\n",
    "        neg_weight=cfg.MODEL.PN2.NEG_WEIGHT,\n",
    "    )\n",
    "    metric = PointNet2Metric()\n",
    "\n",
    "    return net, loss_func, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/po/TM5/graspnetAPI'\n",
    "valid_obj_idxs, grasp_labels = load_grasp_labels(root)\n",
    "train_dataset = GraspNetDataset(root, valid_obj_idxs, grasp_labels, split='train', remove_outlier=True, remove_invisible=True, num_points=20000)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================test\n",
    "\n",
    "# grasp_list = train_dataset.__getitem__(0)['grasp_list']\n",
    "# point_clouds = train_dataset.__getitem__(0)['point_clouds']\n",
    "cfg_path = \"/home/po/TM5/s4g-release/inference/grasp_proposal/configs/curvature_model.yaml\"\n",
    "cfg = load_cfg_from_file(cfg_path)\n",
    "cfg.defrost()\n",
    "# cfg.TEST.WEIGHT = cfg.TEST.WEIGHT.replace(\"${PROJECT_HOME}\", os.path.join(os.getcwd(), \"../\"))\n",
    "# cfg.TEST.WEIGHT = '/home/po/TM5/s4g-release/inference/trained_models/curvature_model.pth'\n",
    "cfg.TEST.WEIGHT = cfg.TEST.WEIGHT.replace(\"${PROJECT_HOME}\", os.path.join('/home/po/TM5/s4g-release/inference'))\n",
    "cfg.freeze()\n",
    "assert cfg.TEST.BATCH_SIZE == 1\n",
    "model, loss_func, _ = build_model(cfg)\n",
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "# tmp = torch.ones(1,3,20000)\n",
    "data_batch = {\n",
    "        \"point_clouds\": tmp_dic['point_clouds'].permute(0,2,1).float().cuda(),\n",
    "#         \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"q_label\": tmp_dic[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"score_label\": tmp_dic[\"score_label\"].permute(0,2,1).float().cuda(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_batch['point_clouds'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "# print(tmp_dic[\"score_label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_dic['score_label'].shape\n",
    "# score_label = labels[\"score_label\"]#.permute(0,2,1).unsqueeze(-1)\n",
    "# score_pred = preds[\"score_pred\"]\n",
    "# score_loss = self.loss2(score_pred,score_label)\n",
    "FF = torch.tensor([[[1., 1., 1., 1., 1.]]])\n",
    "DD = torch.tensor([[[2., 3., 4., 5., 6.]]])\n",
    "loss2_func = nn.MSELoss()\n",
    "loss2_func(DD,FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp.shape\n",
    "pred= model(data_batch)\n",
    "print(pred['score_pred'].shape,pred['q_pred'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eaf216",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(pred,data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[[1., 1., 1., 1., 1.],\n",
    "         [-1., 1., 1., 1., 1.],\n",
    "         [10., 1., 1., 1., 1.]]])\n",
    "B_pre = torch.tensor([[[2., 2., 1., 1., 1.],\n",
    "         [2., 4., 1., 1., 1.],\n",
    "         [3., 4., 1., 1., 1.]]])\n",
    "print(A.shape,B_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_T = A.permute(0,2,1)\n",
    "B_pre_T = B_pre.permute(0,2,1)\n",
    "print(A_T.shape,B_pre_T.shape)\n",
    "print(A_T)\n",
    "print(B_pre_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = F.normalize(B, dim=1)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b842d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss1_fun = nn.L1Loss(reduce=False)\n",
    "# loss1_fun(B_pre_T,A_T)\n",
    "G = ((B_pre_T - A_T)**2)\n",
    "len(G[0])\n",
    "tmp_G = torch.zeros(1,len(G[0]),1)\n",
    "for i in range(len(G[0])):\n",
    "    tmp_G[0,i,0] = G[0,i,0]+G[0,i,1]+G[0,i,2]\n",
    "print(G.shape)\n",
    "print(tmp_G.shape)\n",
    "G_sqrt = torch.sqrt(tmp_G, out=None)\n",
    "print('G_sqrt',G_sqrt)\n",
    "values, indices = G_sqrt.topk(dim=1,k=3)\n",
    "# values.sum()\n",
    "values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================test\n",
    "\n",
    "# print(grasp_list.shape,point_clouds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5348dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "sys.path.append('/home/po/TM5/graspnet-baseline/pointnet2')\n",
    "\n",
    "from pytorch_utils import BNMomentumScheduler\n",
    "\n",
    "# Init datasets and dataloaders \n",
    "def my_worker_init_fn(worker_id):\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATALOADER = DataLoader(train_dataset, batch_size=2, shuffle=True,\n",
    "    num_workers=4, worker_init_fn=my_worker_init_fn, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a259e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_dic = next(iter(TRAIN_DATALOADER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_dic[\"point_clouds\"].permute(0,2,1).float().shape\n",
    "tmp_dic[\"point_clouds\"].permute(0,2,1).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6efa1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposal_test.py\n",
    "import sys,os\n",
    "sys.path.append('/home/po/TM5/s4g-release/inference')\n",
    "import numpy as np\n",
    "import open3d\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from grasp_proposal.cloud_processor.cloud_processor import CloudPreProcessor\n",
    "from grasp_proposal.configs.yacs_config import load_cfg_from_file\n",
    "# from grasp_proposal.network_models.models.build_model import build_model\n",
    "from grasp_proposal.utils.checkpoint import CheckPointer\n",
    "from grasp_proposal.utils.file_logger_cls import loggin_to_file\n",
    "from grasp_proposal.utils.grasp_visualizer import GraspVisualizer\n",
    "from grasp_proposal.utils.logger import setup_logger, MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposal_test.py\n",
    "# load_static batch data\n",
    "# \n",
    "cfg_path = \"/home/po/TM5/s4g-release/inference/grasp_proposal/configs/curvature_model.yaml\"\n",
    "cfg = load_cfg_from_file(cfg_path)\n",
    "cfg.defrost()\n",
    "# cfg.TEST.WEIGHT = cfg.TEST.WEIGHT.replace(\"${PROJECT_HOME}\", os.path.join(os.getcwd(), \"../\"))\n",
    "# cfg.TEST.WEIGHT = '/home/po/TM5/s4g-release/inference/trained_models/curvature_model.pth'\n",
    "cfg.TEST.WEIGHT = cfg.TEST.WEIGHT.replace(\"${PROJECT_HOME}\", os.path.join('/home/po/TM5/s4g-release/inference'))\n",
    "cfg.freeze()\n",
    "assert cfg.TEST.BATCH_SIZE == 1\n",
    "\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "logger = setup_logger(\"S4G\", output_dir, \"unit_test\")\n",
    "logger.info(\"Using {} of GPUs\".format(torch.cuda.device_count()))\n",
    "logger.info(\"Load config file from {}\".format(cfg_path))\n",
    "logger.debug(\"Running with config \\n {}\".format(cfg))\n",
    "\n",
    "model, loss_func, _ = build_model(cfg)\n",
    "loss_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040801a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func['score_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab45645",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = {'a':1,'b':1,'c':1}\n",
    "\n",
    "sum(loss.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248db90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay_steps = '8,12,16'\n",
    "lr_decay_rates = '0.1,0.1,0.1'\n",
    "EPOCH_CNT = 0\n",
    "LR_DECAY_STEPS = [int(x) for x in lr_decay_steps.split(',')]\n",
    "LR_DECAY_RATES = [float(x) for x in lr_decay_rates.split(',')]\n",
    "assert(len(LR_DECAY_STEPS)==len(LR_DECAY_RATES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebba093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    adjust_learning_rate(optimizer, EPOCH_CNT)\n",
    "    bnm_scheduler.step() # decay BN momentum\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    for batch_idx, batch_data_label in enumerate(tqdm(TRAIN_DATALOADER)):\n",
    "        data_batch = {\n",
    "        \"point_clouds\": batch_data_label[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "#         \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"q_label\": batch_data_label[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "#         \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "            \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).float().cuda(),\n",
    "        }\n",
    "        \n",
    "        predictions = model(data_batch)\n",
    "    \n",
    "    #     print(batch_idx)\n",
    "    #     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "    #     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "        loss = loss_func(predictions, data_batch)\n",
    "        \n",
    "        if ((batch_idx%10) == 0):\n",
    "            print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        sum(loss.values()).backward()   \n",
    "        optimizer.step()\n",
    "        \n",
    "    return loss\n",
    "def evaluate_one_epoch():\n",
    "    model.train()\n",
    "    for batch_idx, batch_data_label in enumerate(TRAIN_DATALOADER):\n",
    "        data_batch = {\n",
    "        \"point_clouds\": batch_data_label[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "        \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"q_label\": batch_data_label[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            predictions = model(data_batch)\n",
    "    #     print(batch_idx)\n",
    "    #     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "    #     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "        loss = loss_func(predictions, data_batch)\n",
    "        sum(loss.values())\n",
    "        \n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "learning_rate = 0.001\n",
    "def get_current_lr(epoch):\n",
    "    lr = learning_rate\n",
    "    for i,lr_decay_epoch in enumerate(LR_DECAY_STEPS):\n",
    "        if epoch >= lr_decay_epoch:\n",
    "            lr *= LR_DECAY_RATES[i]\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "LOG_FOUT = open(os.path.join('/home/po/TM5/s4g-release/inference/grasp_proposal/network_models/models', 'log_train.txt'), 'a')\n",
    "\n",
    "def log_string(out_str):\n",
    "    LOG_FOUT.write(out_str+'\\n')\n",
    "    LOG_FOUT.flush()\n",
    "    print(out_str)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "bn_decay_step = 2\n",
    "bn_decay_rate = 0.5\n",
    "start_epoch = 0\n",
    "BN_MOMENTUM_INIT = 0.5\n",
    "BN_MOMENTUM_MAX = 0.001\n",
    "bn_lbmd = lambda it: max(BN_MOMENTUM_INIT * bn_decay_rate**(int(it / bn_decay_step)), BN_MOMENTUM_MAX)\n",
    "bnm_scheduler = BNMomentumScheduler(model, bn_lambda=bn_lbmd, last_epoch=start_epoch-1)\n",
    "\n",
    "min_loss = 1e10\n",
    "loss = 0\n",
    "global EPOCH_CNT\n",
    "trained_model_path = output_dir\n",
    "check_pointer = CheckPointer(model, save_dir=trained_model_path, logger=logger)\n",
    "for epoch in range(10):\n",
    "    EPOCH_CNT = epoch\n",
    "    log_string('**** EPOCH %03d ****' % (epoch))\n",
    "    log_string('Current learning rate: %f'%(get_current_lr(epoch)))\n",
    "    log_string('Current BN decay momentum: %f'%(bnm_scheduler.lmbd(bnm_scheduler.last_epoch)))\n",
    "    log_string(str(datetime.now()))\n",
    "    # Reset numpy seed.\n",
    "    # REF: https://github.com/pytorch/pytorch/issues/5059\n",
    "    np.random.seed()\n",
    "    loss = train_one_epoch()\n",
    "    print(epoch,loss)\n",
    "    torch.save(model.state_dict(), '{}_graspv1.pth'.format(epoch))\n",
    "#     loss = evaluate_one_epoch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'graspv1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _ = build_model(cfg)\n",
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "# model.load_state_dict(torch.load('0_graspv1.pth'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data_batch = {\n",
    "        \"point_clouds\": tmp_dic[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "        \"xyz_label\": tmp_dic[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"q_label\": tmp_dic[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"score_label\": tmp_dic[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "        }\n",
    "#     tac = time.time()\n",
    "#     data_time = tac - tic\n",
    "    predictions = model(data_batch)\n",
    "#     tic = time.time()\n",
    "#     batch_time = tic - tac\n",
    "#     with open(\"inference_time_{}.txt\".format(\"ours\"), \"a+\") as f:\n",
    "#         f.write(\"{:.4f}\\n\".format(batch_time * 1000.0))\n",
    "#     meters.update(time=batch_time, data=data_time)\n",
    "\n",
    "#     logger.info(meters.delimiter.join([\"{meters}\", ]).format(meters=str(meters), ))\n",
    "\n",
    "#     top_poses, score = loggin_to_file(data_batch, predictions, 0, output_dir, prefix=\"test\", with_label=False)\n",
    "#     visualizer = GraspVisualizer(pcd)\n",
    "#     visualizer.add_multiple_poses(top_poses)\n",
    "#     visualizer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeffe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_grasp_scene(data_batch,predictions):\n",
    "predictions = model(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5825ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tmp_dic['point_clouds'].squeeze(0).shape,tmp_dic['cloud_colors'].squeeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b50596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test open3d \n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3711f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp[12]\n",
    "tmp_dic['score_label'].squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp_dic['score_label'].squeeze(0)\n",
    "tmp2 = tmp_dic['q_label'].squeeze(0)\n",
    "\n",
    "# GG = tmp_dic['q_label']\n",
    "A = []\n",
    "for i in range(20000):\n",
    "    if ((tmp[i,0]>0)):#&(tmp2[i,2]>0.1)):\n",
    "        A.append(i)\n",
    "len(A)\n",
    "for i in A:\n",
    "    print(tmp[i],len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ccdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dic['q_label'].squeeze(0).permute(1,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_q = predictions['q_pred'].squeeze(0).permute(1,0)\n",
    "pred_score = predictions['score_pred'].squeeze(0).permute(1,0)\n",
    "B = []\n",
    "for i in range(20000):\n",
    "#     if torch.ge(pred_score[i,0],torch.tensor([0.], dtype=torch.float64).cuda()):\n",
    "    if ((pred_q[i,0]>0.02)&(pred_q[i,1]>0.02)):\n",
    "        B.append(i)\n",
    "len(B)\n",
    "for i in B:\n",
    "    print(pred_score[i],len(B),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_q[5457].norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a62265",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dic['q_label'].squeeze(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = tmp_dic['point_clouds'].squeeze(0)\n",
    "colors = tmp_dic['cloud_colors'].squeeze(0)\n",
    "print(points.shape,colors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.norm(predictions['q_pred'].squeeze(0).permute(1,0)[66],p=2)\n",
    "# predictions['score_pred'].squeeze(0).squeeze(0).shape\n",
    "predictions['xyz_pred'].squeeze(0).permute(1,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/po/TM5/graspnet-baseline/dataset/'\n",
    "savegrasp_path = 'pre_grasp_v3'\n",
    "savepoints_path = 'pre_point_cloud_v3'\n",
    "savecolor_path = 'pre_color_v3'\n",
    "data_grasp = 'pre_grasp'\n",
    "data_point_clouds = 'pre_point_clouds'\n",
    "data_color ='pre_color'\n",
    "index = 3\n",
    "pre_points = np.load('{}/{}_{}.npy'.format(root_path + savepoints_path, index,data_point_clouds))\n",
    "pre_color = np.load('{}/{}_{}.npy'.format(root_path + savecolor_path, index,data_color))\n",
    "pre_grasp = np.load('{}/{}_{}.npy'.format(root_path + savegrasp_path, index,data_grasp))\n",
    "xyz_label = pre_grasp[:,0:3]\n",
    "q_label = pre_grasp[:,3:7]\n",
    "score_label = pre_grasp[:,7:8]\n",
    "A = []\n",
    "for i in range(len(score_label)):\n",
    "    if score_label[i,0] > 0:\n",
    "        A.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33edbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93732f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test  open3d\n",
    "from graspnetAPI import GraspNet, Grasp, GraspGroup\n",
    "from pyquaternion import Quaternion\n",
    "from utils import trans3d\n",
    "axis_pcd = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "# axis_pcd_tx = copy.deepcopy(axis_pcd).translate((1.3,0,0))\n",
    "# points = np.array([[0.1, 0.1, 0.1], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "# colors = [[1, 1, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "points = pre_points#tmp_dic['point_clouds'].squeeze(0)\n",
    "colors = pre_color#tmp_dic['cloud_colors'].squeeze(0)\n",
    "test_pcd = o3d.geometry.PointCloud()  # 定义点云\n",
    "test_pcd.points = o3d.utility.Vector3dVector(points)  # 定义点云坐标位置\n",
    "test_pcd.colors = o3d.utility.Vector3dVector(colors)  # 定义点云的颜色\n",
    "gg = GraspGroup()\n",
    "count = 0\n",
    "max_count =200\n",
    "for i in A:\n",
    "    if count == max_count:\n",
    "        break\n",
    "    count = count + 1\n",
    "#     xyz = tmp_dic['point_clouds'].squeeze(0)[i] ori\n",
    "    xyz = xyz_label[i]#tmp_dic['point_clouds'].squeeze(0)[i]\n",
    "#     xyz = predictions['xyz_pred'].squeeze(0).permute(1,0)[i].cpu()\n",
    "#     q = predictions['q_pred'].squeeze(0).permute(1,0)[i] ori\n",
    "    q = q_label[i]#tmp_dic['q_label'].squeeze(0)[i]\n",
    "#     score = predictions['score_pred'].squeeze(0).squeeze(0)[i]\n",
    "#     print('i:',i,score)#,xyz,q)\n",
    "    print(xyz,q)\n",
    "    tmp_m = trans3d.pos_quat_to_pose_4x4(xyz,q)\n",
    "    g = Grasp()\n",
    "    g.width = 0.07\n",
    "    g.transform(tmp_m)\n",
    "    gg.add(g)\n",
    "    \n",
    "# xyz = tmp_dic['xyz_label'].squeeze(0)[12]\n",
    "# q = tmp_dic['q_label'].squeeze(0)[12]\n",
    "# tmp_m = trans3d.pos_quat_to_pose_4x4(xyz,q)\n",
    "# g = Grasp()\n",
    "# g.width = 0.04\n",
    "# g.transform(tmp_m)\n",
    "# gg = GraspGroup()\n",
    "# gg.add(g)\n",
    "geometries = [axis_pcd,test_pcd,*gg.to_open3d_geometry_list()]\n",
    "# geometries = [axis_pcd,test_pcd,g.to_open3d_geometry()]\n",
    "# geometries.append(axis_pcd)\n",
    "\n",
    "o3d.visualization.draw_geometries(geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test  open3d\n",
    "from graspnetAPI import GraspNet, Grasp, GraspGroup\n",
    "from pyquaternion import Quaternion\n",
    "from utils import trans3d\n",
    "axis_pcd = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "# axis_pcd_tx = copy.deepcopy(axis_pcd).translate((1.3,0,0))\n",
    "# points = np.array([[0.1, 0.1, 0.1], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "# colors = [[1, 1, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "points = tmp_dic['point_clouds'].squeeze(0)\n",
    "colors = tmp_dic['cloud_colors'].squeeze(0)\n",
    "test_pcd = o3d.geometry.PointCloud()  # 定义点云\n",
    "test_pcd.points = o3d.utility.Vector3dVector(points)  # 定义点云坐标位置\n",
    "test_pcd.colors = o3d.utility.Vector3dVector(colors)  # 定义点云的颜色\n",
    "gg = GraspGroup()\n",
    "count = 0\n",
    "max_count = 20000 \n",
    "for i in A:\n",
    "    if count == max_count:\n",
    "        break\n",
    "    count = count + 1\n",
    "    xyz = tmp_dic['xyz_label'].squeeze(0)[i]\n",
    "    q = tmp_dic['q_label'].squeeze(0)[i]\n",
    "    tmp_m = trans3d.pos_quat_to_pose_4x4(xyz,q)\n",
    "    g = Grasp()\n",
    "    g.width = 0.04\n",
    "    g.transform(tmp_m)\n",
    "    gg.add(g)\n",
    "    \n",
    "# xyz = tmp_dic['xyz_label'].squeeze(0)[12]\n",
    "# q = tmp_dic['q_label'].squeeze(0)[12]\n",
    "# tmp_m = trans3d.pos_quat_to_pose_4x4(xyz,q)\n",
    "# g = Grasp()\n",
    "# g.width = 0.04\n",
    "# g.transform(tmp_m)\n",
    "# gg = GraspGroup()\n",
    "# gg.add(g)\n",
    "geometries = [axis_pcd,test_pcd,*gg.to_open3d_geometry_list()]\n",
    "# geometries = [axis_pcd,test_pcd,g.to_open3d_geometry()]\n",
    "# geometries.append(axis_pcd)\n",
    "\n",
    "o3d.visualization.draw_geometries(geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb040681",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspnetAPI import GraspNet, Grasp, GraspGroup\n",
    "from pyquaternion import Quaternion\n",
    "from utils import trans3d\n",
    "frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "\n",
    "# print(tmp_dic['xyz_label'].squeeze(0)[118],tmp_dic['q_label'].squeeze(0)[118])\n",
    "xyz = tmp_dic['xyz_label'].squeeze(0)[118]\n",
    "q = tmp_dic['q_label'].squeeze(0)[118]\n",
    "tmp_m = trans3d.pos_quat_to_pose_4x4(xyz,q)\n",
    "g = Grasp()\n",
    "g.transform(tmp_m)\n",
    "gg = GraspGroup()\n",
    "gg.add(g)\n",
    "print(g)\n",
    "points = tmp_dic['point_clouds'].squeeze(0)\n",
    "colors = tmp_dic['cloud_colors'].squeeze(0)\n",
    "test_pcd = open3d.geometry.PointCloud()  # 定义点云\n",
    "geometries = [frame,test_pcd,*gg.to_open3d_geometry_list()]\n",
    "o3d.visualization.draw_geometries(geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c671e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "model.train()\n",
    "\n",
    "for batch_idx, batch_data_label in enumerate(TRAIN_DATALOADER):\n",
    "    data_batch = {\n",
    "    \"point_clouds\": batch_data_label[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "    \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "    \"q_label\": batch_data_label[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "    \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "    }\n",
    "    predictions = model(data_batch)\n",
    "    print(batch_idx)\n",
    "#     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "#     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "    loss = loss_func(predictions, data_batch)\n",
    "    sum(loss.values()).backward()   \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "#     model.save\n",
    "#     print(loss['xyz_loss'],loss['q_loss'],loss['score_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14cd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss(predictions, data_batch1)\n",
    "loss_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5fcb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gripper_pro_max(center, R, width, depth, score=1, color=None):\n",
    "    '''\n",
    "    Author: chenxi-wang\n",
    "    \n",
    "    **Input:**\n",
    "\n",
    "    - center: numpy array of (3,), target point as gripper center\n",
    "\n",
    "    - R: numpy array of (3,3), rotation matrix of gripper\n",
    "\n",
    "    - width: float, gripper width\n",
    "\n",
    "    - score: float, grasp quality score\n",
    "\n",
    "    **Output:**\n",
    "\n",
    "    - open3d.geometry.TriangleMesh\n",
    "    '''\n",
    "    x, y, z = center\n",
    "    height=0.004\n",
    "    finger_width = 0.004\n",
    "    tail_length = 0.04\n",
    "    depth_base = 0.02\n",
    "    \n",
    "    if color is not None:\n",
    "        color_r, color_g, color_b = color\n",
    "    else:\n",
    "        color_r = score # red for high score\n",
    "        color_g = 0\n",
    "        color_b = 1 - score # blue for low score\n",
    "    \n",
    "    left = create_mesh_box(depth+depth_base+finger_width, finger_width, height)\n",
    "    right = create_mesh_box(depth+depth_base+finger_width, finger_width, height)\n",
    "    bottom = create_mesh_box(finger_width, width, height)\n",
    "    tail = create_mesh_box(tail_length, finger_width, height)\n",
    "\n",
    "    left_points = np.array(left.vertices)\n",
    "    left_triangles = np.array(left.triangles)\n",
    "    left_points[:,0] -= depth_base + finger_width\n",
    "    left_points[:,1] -= width/2 + finger_width\n",
    "    left_points[:,2] -= height/2\n",
    "\n",
    "    right_points = np.array(right.vertices)\n",
    "    right_triangles = np.array(right.triangles) + 8\n",
    "    right_points[:,0] -= depth_base + finger_width\n",
    "    right_points[:,1] += width/2\n",
    "    right_points[:,2] -= height/2\n",
    "\n",
    "    bottom_points = np.array(bottom.vertices)\n",
    "    bottom_triangles = np.array(bottom.triangles) + 16\n",
    "    bottom_points[:,0] -= finger_width + depth_base\n",
    "    bottom_points[:,1] -= width/2\n",
    "    bottom_points[:,2] -= height/2\n",
    "\n",
    "    tail_points = np.array(tail.vertices)\n",
    "    tail_triangles = np.array(tail.triangles) + 24\n",
    "    tail_points[:,0] -= tail_length + finger_width + depth_base\n",
    "    tail_points[:,1] -= finger_width / 2\n",
    "    tail_points[:,2] -= height/2\n",
    "\n",
    "    vertices = np.concatenate([left_points, right_points, bottom_points, tail_points], axis=0)\n",
    "    vertices = np.dot(R, vertices.T).T + center\n",
    "    triangles = np.concatenate([left_triangles, right_triangles, bottom_triangles, tail_triangles], axis=0)\n",
    "    colors = np.array([ [color_r,color_g,color_b] for _ in range(len(vertices))])\n",
    "\n",
    "    gripper = o3d.geometry.TriangleMesh()\n",
    "    gripper.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "    gripper.triangles = o3d.utility.Vector3iVector(triangles)\n",
    "    gripper.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "    return gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc574737",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "    \n",
    "model.eval()\n",
    "data_batch = {\n",
    "\"point_clouds\": tmp_dic['point_clouds'].permute(0,2,1).float().cuda(),\n",
    "\"xyz_label\": tmp_dic['xyz_label'].permute(0,2,1).float().cuda(),\n",
    "\"q_label\": tmp_dic['q_label'].permute(0,2,1).float().cuda(),\n",
    "\"score_label\": tmp_dic['score_label'].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "}\n",
    "predictions = model(data_batch)\n",
    "# print(batch_idx)\n",
    "#     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "#     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "loss = loss(predictions, data_batch)\n",
    "# sum(loss.values()).backward()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a685c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_dic['point_clouds'].shape,tmp_dic['xyz_label'].shape,tmp_dic['q_label'].shape,tmp_dic['score_label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.keys())\n",
    "print(predictions['score_pred'].shape,predictions['q_pred'].shape,predictions['xyz_pred'].shape)\n",
    "print(data_batch['score_label'].shape,data_batch['q_label'].permute(0,2,1).shape,data_batch['xyz_label'].permute(0,2,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = torch.tensor([[[2., 2., 2.],\n",
    "#          [3., 3., 3.]],\n",
    "\n",
    "#         [[4., 4., 4.],\n",
    "#          [5., 5., 6.]]])\n",
    "# B = torch.tensor([[[1., 1., 1.],\n",
    "#          [1., 1., 1.]],\n",
    "\n",
    "#         [[1., 1., 1.],\n",
    "#          [1., 1., 1.]]])\n",
    "A = torch.ones(1,4,20000)\n",
    "B = torch.ones(1,4,20000)\n",
    "D = (A -B)**2\n",
    "E = ((A -B)**2).mean(1,True)\n",
    "print(D.shape,E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2614ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_label = data_batch[\"q_label\"].permute(0,2,1)#(1,4,20)\n",
    "q_pred = predictions[\"q_pred\"]\n",
    "q_loss = ((q_pred - q_label) ** 2).mean(1, True)\n",
    "\n",
    "q_loss.shape\n",
    "# # weight loss according to gt_score\n",
    "# score_label = labels[\"score_label\"].permute(0,2,1).unsqueeze(-1)\n",
    "# score_pred = preds[\"score_pred\"]\n",
    "# score_loss = ((score_pred - score_label) ** 2).mean(1, True)\n",
    "\n",
    "\n",
    "# xyz_label = labels[\"xyz_label\"].permute(0,2,1)\n",
    "# xyz_pred = preds[\"xyz_pred\"]\n",
    "# xyz_loss = ((xyz_pred - xyz_label) ** 2).mean(1, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac97a07",
   "metadata": {},
   "source": [
    "q_label = q_label.permute(0,2,1)\n",
    "q_label.shape\n",
    "xyz_label.permute(0,2,1).shape\n",
    "score_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions['score_pred'].shape,predictions['q_pred'].shape,predictions['xyz_pred'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn2_loss_fn = loss().cuda()\n",
    "loss = pn2_loss_fn(predictions, data_batch)\n",
    "loss['xyz_loss'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e316b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/po/TM5/s4g-release/inference')\n",
    "import numpy as np\n",
    "import open3d\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from grasp_proposal.cloud_processor.cloud_processor import CloudPreProcessor\n",
    "from grasp_proposal.configs.yacs_config import load_cfg_from_file\n",
    "from grasp_proposal.network_models.models.build_model import build_model\n",
    "from grasp_proposal.utils.checkpoint import CheckPointer\n",
    "from grasp_proposal.utils.file_logger_cls import loggin_to_file\n",
    "from grasp_proposal.utils.grasp_visualizer import GraspVisualizer\n",
    "from grasp_proposal.utils.logger import setup_logger, MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_training_data = np.load(\"/home/po/TM5/s4g-release/2638_view_0.p\", allow_pickle=True)\n",
    "# cloud_array = single_training_data[\"point_cloud\"]\n",
    "# cloud = CloudPreProcessor(open3d.geometry.PointCloud(open3d.utility.Vector3dVector(cloud_array.T)), False)\n",
    "# # do not filter workspace here since training data\n",
    "# cloud.voxelize()\n",
    "# cloud.remove_outliers()\n",
    "# points = np.asarray(cloud.pcd.points)\n",
    "# if points.shape[0] > 25600:\n",
    "#     random_index = np.random.choice(np.arange(points.shape[0]), 25600, replace=False)\n",
    "# else:\n",
    "#     random_index = np.random.choice(np.arange(points.shape[0]), 25600, replace=True)\n",
    "\n",
    "# points = points[random_index, :]\n",
    "# C = torch.tensor(points, dtype=torch.float32).unsqueeze(0).transpose(1, 2)\n",
    "# B = torch.tensor(points, dtype=torch.float32).unsqueeze(0)\n",
    "# A = torch.tensor(points, dtype=torch.float32)\n",
    "# # data_batch = {\"scene_points\": torch.tensor(points, dtype=torch.float32).unsqueeze(0).transpose(1, 2)}\n",
    "# # print(data_batch,cloud.pcd)\n",
    "# print(A.shape,B.shape,C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_training_data['point_cloud'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d886519",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = torch.ones(1, 9, 25600) \n",
    "t = torch.ones(1, 3, 25600)\n",
    "local_search_frame = torch.cat([R, t], dim=1).unsqueeze(-1)\n",
    "local_search_frame = local_search_frame.repeat(1, 4, 1, 1)\n",
    "# sparse_feature = sparse_feature.unsqueeze(-1)\n",
    "# valid_feature = torch.cat([sparse_feature, local_search_frame], dim=1)\n",
    "# local_search_logit = self.grasp_eval_logit(self.mlp_grasp_eval(valid_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20217f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search_frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquaternion import Quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2a35f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quaternion(0.9848077012197697, 0.17364818258237882, 0.0, 0.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rx_180 = Quaternion(0,1,0,0)#(w,x,y,z)\n",
    "Rx_160 = Quaternion(0.1736482,0.9848078, 0, 0)#(w,x,y,z)\n",
    "Result = (Rx_180*(Rx_160.inverse))\n",
    "# Result.norm\n",
    "Result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "N180 = np.array([Rx_180.w,Rx_180.x,Rx_180.y,Rx_180.z])\n",
    "N160 = np.array([-Rx_160.w,Rx_160.x,Rx_160.y,Rx_160.z])\n",
    "N180*N160.T\n",
    "ls = value.X * value.X + value.Y * value.Y + value.Z * value.Z + value.W * value.W;\n",
    "invNorm = 1.0f / ls;\n",
    "\n",
    "ans.X = -value.X * invNorm;\n",
    "ans.Y = -value.Y * invNorm;\n",
    "ans.Z = -value.Z * invNorm;\n",
    "ans.W = value.W * invNorm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73360107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch3d\n",
    "from pytorch3d import transforms\n",
    "# import numpy as np\n",
    "q = torch.tensor([1,0,0,0])\n",
    "unit_q = transforms.standardize_quaternion(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "585aaecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9848, 0.1736, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rx180 = torch.tensor([0,1,0,0])\n",
    "Rx160 = torch.tensor([0.1736482,0.9848078, 0, 0])\n",
    "# Rx160.inverse\n",
    "Rx160_inverse = pytorch3d.transforms.quaternion_invert(Rx160)\n",
    "Result1 = pytorch3d.transforms.quaternion_multiply(a =Rx180,b=Rx160_inverse)\n",
    "Result1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6271b290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1736, -0.9848, -0.0000, -0.0000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rx160_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1ff2fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_q = torch.cat((torch.ones(1,6,1),torch.zeros(1,6,3)),dim=2)\n",
    "# aa = transforms.quaternion_to_matrix(unit_q)\n",
    "# aa.shape\n",
    "unit_q.norm(dim=2,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36e69874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {\"score_label\":torch.randn(1,1,20000),\"q_label\":torch.randn(1,1,20000)}\n",
    "preds = {\"score_pred\":torch.randn(1,4,20000),\"q_pred\":torch.randn(1,4,20000)}\n",
    "\n",
    "score_label = labels[\"score_label\"].permute(0,2,1)#.unsqueeze(-1) #(1,20000,1)\n",
    "score_pred = preds[\"score_pred\"].permute(0,2,1)  #(1,20000,1)\n",
    "score_loss = torch.pow((score_pred - score_label), 2)  #torch.Size([1, 20000, 4])\n",
    "\n",
    "values_score , indice_score = torch.topk(score_loss, 400, dim=1, largest=True, sorted=True, out=None)\n",
    "loss1 = torch.mean(values_score)\n",
    "\n",
    "q_label = labels[\"q_label\"].permute(0,2,1)#(1,20000,4)\n",
    "q_pred = preds[\"q_pred\"].permute(0,2,1) #(1,20000,4)\n",
    "unit_q = torch.cat((torch.ones(1,20000,1),torch.zeros(1,20000,3)),dim=2) #torch.Size([1, 20000, 4])\n",
    "q_label_inverse = pytorch3d.transforms.quaternion_invert(q_label) #torch.Size([1, 20000, 4])\n",
    "Result1 = pytorch3d.transforms.quaternion_multiply(a =q_pred,b=q_label_inverse)#torch.Size([1, 20000, 4])\n",
    "Result2 = pytorch3d.transforms.standardize_quaternion(Result1)#torch.Size([1, 20000, 4])\n",
    "Result3 = Result2 - unit_q#torch.Size([1, 20000, 4])\n",
    "q_loss = Result3.norm(dim=2,keepdim=True)#torch.Size([1, 20000, 1])\n",
    "values_q, indice_q = torch.topk(q_loss, 400, dim=1, largest=True, sorted=True, out=None)\n",
    "loss2 = torch.mean(values_q)\n",
    "values_q.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
