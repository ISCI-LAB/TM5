{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0103b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please compile source files before using functions CUDA extension.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/pointnet2-0.0.0-py3.6-linux-x86_64.egg',\n",
       " '/usr/local/lib/python3.6/dist-packages/knn_pytorch-0.1-py3.6-linux-x86_64.egg',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/home/po/.ipython',\n",
       " '/home/po/TM5/s4g-release/inference/grasp_proposal/network_models',\n",
       " '/home/po/TM5/graspnetAPI/graspnetAPI',\n",
       " '/home/po/TM5']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os, sys\n",
    "import sys\n",
    "from torchsummary import summary\n",
    "# sys.path.append('/home/po/TM5/Pointnet_Pointnet2_pytorch')\n",
    "sys.path.append('/home/po/TM5/s4g-release/inference/grasp_proposal/network_models')\n",
    "sys.path.append('/home/po/TM5/graspnetAPI/graspnetAPI')\n",
    "sys.path.append('/home/po/TM5')\n",
    "from nn_utils.mlp import SharedMLP\n",
    "from pointnet2_utils.modules import PointNetSAModule, PointnetFPModule, PointNetSAAvgModule\n",
    "from nn_utils.functional import smooth_cross_entropy\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed0c30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2021-11-30 14:45:30,046 - rigid_transformations - Failed to import geometry msgs in rigid_transformations.py.\n",
      "WARNING - 2021-11-30 14:45:30,047 - rigid_transformations - Failed to import ros dependencies in rigid_transforms.py\n",
      "WARNING - 2021-11-30 14:45:30,048 - rigid_transformations - autolab_core not installed as catkin package, RigidTransform ros methods will be unavailable\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/home/po/TM5/graspnet-baseline')\n",
    "import scipy.io as scio\n",
    "from dataset.graspnet_dataset1 import GraspNetDataset, collate_fn, load_grasp_labels\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1828e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2(nn.Module):\n",
    "    \"\"\"PointNet++ part segmentation with single-scale grouping\n",
    "\n",
    "    PointNetSA: PointNet Set Abstraction Layer\n",
    "    PointNetFP: PointNet Feature Propagation Layer\n",
    "\n",
    "    Args:\n",
    "        score_classes (int): the number of grasp score classes\n",
    "        num_centroids (tuple of int): the numbers of centroids to sample in each set abstraction module\n",
    "        radius (tuple of float): a tuple of radius to query neighbours in each set abstraction module\n",
    "        num_neighbours (tuple of int): the numbers of neighbours to query for each centroid\n",
    "        sa_channels (tuple of tuple of int): the numbers of channels within each set abstraction module\n",
    "        fp_channels (tuple of tuple of int): the numbers of channels for feature propagation (FP) module\n",
    "        num_fp_neighbours (tuple of int): the numbers of nearest neighbor used in FP\n",
    "        seg_channels (tuple of int): the numbers of channels in segmentation mlp\n",
    "        dropout_prob (float): the probability to dropout input features\n",
    "\n",
    "    References:\n",
    "        https://github.com/charlesq34/pointnet2/blob/master/models/pointnet2_part_seg.py\n",
    "\n",
    "    \"\"\"\n",
    "    _SA_MODULE = PointNetSAModule\n",
    "    _FP_MODULE = PointnetFPModule\n",
    "\n",
    "    def __init__(self,\n",
    "                 score_classes,\n",
    "                 num_centroids=(10240, 1024, 128, 0),\n",
    "                 radius=(0.2, 0.3, 0.4, -1.0),\n",
    "                 num_neighbours=(64, 64, 64, -1),\n",
    "                 sa_channels=((32, 32, 64), (64, 64, 128), (128, 128, 256), (256, 512, 1024)),\n",
    "                 fp_channels=((256, 256), (256, 128), (128, 128), (64, 64, 64)),\n",
    "                 num_fp_neighbours=(0, 3, 3, 3),\n",
    "                 seg_channels=(128,),\n",
    "                 num_removal_directions=5,\n",
    "                 dropout_prob=0.5):\n",
    "        super(PointNet2, self).__init__()\n",
    "\n",
    "        # Sanity check\n",
    "        num_sa_layers = len(num_centroids)\n",
    "        num_fp_layers = len(fp_channels)\n",
    "        assert len(radius) == num_sa_layers\n",
    "        assert len(num_neighbours) == num_sa_layers\n",
    "        assert len(sa_channels) == num_sa_layers\n",
    "        assert num_sa_layers == num_fp_layers\n",
    "        assert len(num_fp_neighbours) == num_fp_layers\n",
    "\n",
    "        # Set Abstraction Layers\n",
    "        feature_channels = 0\n",
    "        self.sa_modules = nn.ModuleList()\n",
    "        for ind in range(num_sa_layers):\n",
    "            sa_module = self._SA_MODULE(in_channels=feature_channels,\n",
    "                                        mlp_channels=sa_channels[ind],\n",
    "                                        num_centroids=num_centroids[ind],\n",
    "                                        radius=radius[ind],\n",
    "                                        num_neighbours=num_neighbours[ind],\n",
    "                                        use_xyz=True)\n",
    "            self.sa_modules.append(sa_module)\n",
    "            feature_channels = sa_channels[ind][-1]\n",
    "\n",
    "        inter_channels = [0]\n",
    "        inter_channels.extend([x[-1] for x in sa_channels])\n",
    "\n",
    "        # Feature Propagation Layers\n",
    "        self.fp_modules = nn.ModuleList()\n",
    "        feature_channels = inter_channels[-1]\n",
    "        for ind in range(num_fp_layers):\n",
    "            fp_module = self._FP_MODULE(in_channels=feature_channels + inter_channels[-2 - ind],\n",
    "                                        mlp_channels=fp_channels[ind],\n",
    "                                        num_neighbors=num_fp_neighbours[ind])\n",
    "            self.fp_modules.append(fp_module)\n",
    "            feature_channels = fp_channels[ind][-1]\n",
    "\n",
    "        # MLP\n",
    "#         self.mlp_seg = SharedMLP(feature_channels, seg_channels, ndim=1, dropout_prob=dropout_prob)\n",
    "#         self.seg_logit = nn.Conv1d(seg_channels[-1], score_classes, 1, bias=True)\n",
    "\n",
    "        self.mlp_grasp_eval = SharedMLP(feature_channels + 28, seg_channels, ndim=2, dropout_prob=dropout_prob)\n",
    "        self.grasp_eval_logit = nn.Conv2d(seg_channels[-1], 1, 1, bias=True)\n",
    "    \n",
    "        self.mlp_R = SharedMLP(feature_channels, seg_channels, ndim=1)\n",
    "        self.R_logit = nn.Conv1d(seg_channels[-1], 4, 1, bias=True)\n",
    "\n",
    "        self.mlp_t = SharedMLP(feature_channels, seg_channels, ndim=1)\n",
    "        self.t_logit = nn.Conv1d(seg_channels[-1], 3, 1, bias=True)\n",
    "\n",
    "#         self.mlp_movable = SharedMLP(feature_channels, seg_channels, ndim=1, dropout_prob=dropout_prob)\n",
    "#         self.movable_logit = nn.Sequential(\n",
    "#             nn.Conv1d(seg_channels[-1], num_removal_directions, 1, bias=True),\n",
    "#             nn.Sigmoid())\n",
    "\n",
    "        self.init_weights()\n",
    "    def forward(self, data_batch):\n",
    "        points = data_batch[\"point_clouds\"]\n",
    "\n",
    "        xyz = points\n",
    "        feature = None\n",
    "\n",
    "        # save intermediate results\n",
    "        inter_xyz = [xyz]\n",
    "        inter_feature = [feature]\n",
    "\n",
    "        # Set Abstraction Layers\n",
    "        for sa_module in self.sa_modules:\n",
    "            xyz, feature = sa_module(xyz, feature)\n",
    "            inter_xyz.append(xyz)\n",
    "            inter_feature.append(feature)\n",
    "\n",
    "        # Feature Propagation Layers\n",
    "        sparse_xyz = xyz\n",
    "        sparse_feature = feature\n",
    "        for fp_ind, fp_module in enumerate(self.fp_modules):\n",
    "            dense_xyz = inter_xyz[-2 - fp_ind]\n",
    "            dense_feature = inter_feature[-2 - fp_ind]\n",
    "            fp_feature = fp_module(dense_xyz, sparse_xyz, dense_feature, sparse_feature)\n",
    "            sparse_xyz = dense_xyz\n",
    "            sparse_feature = fp_feature\n",
    "\n",
    "        # MLP\n",
    "#         x = self.mlp_seg(sparse_feature)\n",
    "#         logits = self.seg_logit(x)\n",
    "        \n",
    "              \n",
    "        \n",
    "        \n",
    "        R = self.mlp_R(sparse_feature)\n",
    "        R = self.R_logit(R)\n",
    "        R = F.normalize(R, dim=1)\n",
    "        # R = toRotMatrix(R)\n",
    "        # R = euler2RotMatrix(R)\n",
    "\n",
    "        t = self.mlp_t(sparse_feature)\n",
    "        t = self.t_logit(t)\n",
    "        \n",
    "        local_search_frame = torch.cat([R, t], dim=1).unsqueeze(-1)\n",
    "        local_search_frame = local_search_frame.repeat(1, 4, 1, 1)\n",
    "        sparse_feature = sparse_feature.unsqueeze(-1)\n",
    "        valid_feature = torch.cat([sparse_feature, local_search_frame], dim=1)\n",
    "        local_search_logit = self.grasp_eval_logit(self.mlp_grasp_eval(valid_feature))\n",
    "        # t = points + t\n",
    "        \n",
    "#         mov = self.mlp_movable(sparse_feature)\n",
    "#         mov = self.movable_logit(mov)  # (B, 5, N)\n",
    "        \n",
    "            \n",
    "        preds = {\n",
    "#                 \"score\": logits,\n",
    "                \"score_pred\": local_search_logit,\n",
    "                 \"q_pred\": R,\n",
    "                 \"xyz_pred\": t,\n",
    "#                  \"movable_logits\": mov,\n",
    "                 }\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def init_weights(self):\n",
    "        # nn_utils.init.zeros_(self.t_logit.weight)\n",
    "        # nn_utils.init.zeros_(self.t_logit.bias)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1,4,5->20000)\n",
    "A = torch.tensor([[[1., 2., 3., 4., 5.],\n",
    "         [1., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.]]])\n",
    "B = torch.tensor([[[2., 2., 3., 4., 5.],\n",
    "         [5., 2., 3., 4., 5.],\n",
    "         [4., 2., 3., 4., 5.],\n",
    "         [3., 2., 3., 4., 5.]]])\n",
    "C = B-A\n",
    "C\n",
    "F.normalize(C**2,dim=1)\n",
    "# (C**2).mean(1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626501ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input = torch.tensor([[[1., 2., 3., 4., 5.],\n",
    "         [1., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.],\n",
    "         [2., 2., 3., 4., 5.]]])\n",
    "target = torch.tensor([[[3.,4., 3., 4., 5.],\n",
    "         [3., 4., 3., 4., 5.],\n",
    "         [3., 3., 3., 4., 5.],\n",
    "         [3., 3., 3., 4., 5.]]])\n",
    "# output.backward()\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86adce16",
   "metadata": {},
   "source": [
    "R = torch.ones(1,4,20000)\n",
    "t = torch.ones(1,3,20000)\n",
    "sparse_feature = torch.ones(1,256,20000)\n",
    "local_search_frame = torch.cat([R, t], dim=1).unsqueeze(-1)\n",
    "local_search_frame.shape\n",
    "local_search_frame = local_search_frame.repeat(1, 4, 1, 1)\n",
    "sparse_feature = sparse_feature.unsqueeze(-1)\n",
    "valid_feature = torch.cat([sparse_feature, local_search_frame], dim=1)\n",
    "valid_feature.shape\n",
    "# # model.mlp_grasp_eval(valid_feature.cuda())\n",
    "local_search_logit = model.grasp_eval_logit(model.mlp_grasp_eval(valid_feature))\n",
    "local_search_logit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24638f5e",
   "metadata": {},
   "source": [
    "R = torch.tensor([[[1, 0.5000, 0.5000, 0.5000, 0.5000],\n",
    "         [1, 0.5000, 0.5000, 0.5000, 0.5000],\n",
    "         [2, 0.5000, 0.5000, 0.5000, 0.5000],\n",
    "         [2, 0.5000, 0.5000, 0.5000, 0.5000]]])\n",
    "print(R.shape)\n",
    "R = torch.nn.functional.normalize(R, dim=1)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e81c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2Loss(nn.Module):\n",
    "    def __init__(self, label_smoothing=0, neg_weight=0.1):\n",
    "        super(PointNet2Loss, self).__init__()\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.neg_weight = neg_weight\n",
    "        self.loss1 = nn.L1Loss()\n",
    "        self.loss2 = nn.MSELoss()\n",
    "    def forward(self, preds, labels):\n",
    "        \n",
    "\n",
    "        q_label = labels[\"q_label\"]#.permute(0,2,1)#(1,4,20)\n",
    "        q_pred = preds[\"q_pred\"]\n",
    "        q_loss = self.loss1(q_pred,q_label)\n",
    "#         q_loss = ((q_pred - q_label) ** 2).mean(1, True)\n",
    "        \n",
    "\n",
    "        # weight loss according to gt_score\n",
    "        score_label = labels[\"score_label\"]#.permute(0,2,1).unsqueeze(-1)\n",
    "        score_pred = preds[\"score_pred\"]\n",
    "        score_loss = self.loss2(score_pred,score_label)\n",
    "#         score_loss = ((score_pred - score_label) ** 2).mean(1, True)\n",
    "        \n",
    "\n",
    "        xyz_label = labels[\"xyz_label\"]#.permute(0,2,1)\n",
    "        xyz_pred = preds[\"xyz_pred\"]\n",
    "        xyz_loss = self.loss2(xyz_pred,xyz_label)\n",
    "#         xyz_loss = ((xyz_pred - xyz_label) ** 2).mean(1, True)\n",
    "        \n",
    "    \n",
    "\n",
    "        loss_dict = {\n",
    "                    \"score_loss\": score_loss,\n",
    "                     \"q_loss\": q_loss,\n",
    "                     \"xyz_loss\": xyz_loss,\n",
    "                     }\n",
    "\n",
    "        return loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6151910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2Metric(nn.Module):\n",
    "    def forward(self, preds, labels):\n",
    "        scene_score_logits = preds[\"scene_score_logits\"]  # (B, C, N2)\n",
    "        score_classes = scene_score_logits.shape[1]\n",
    "\n",
    "        scene_score_labels = labels[\"scene_score_labels\"]  # (B, N)\n",
    "\n",
    "        selected_preds = scene_score_logits.argmax(1).view(-1)\n",
    "        scene_score_labels = scene_score_labels.view(-1)\n",
    "\n",
    "        cls_acc = selected_preds.eq(scene_score_labels).float()\n",
    "\n",
    "        movable_logits = preds[\"movable_logits\"]\n",
    "        movable_labels = labels[\"scene_movable_labels\"]\n",
    "        movable_preds = (movable_logits > 0.5).view(-1).int()\n",
    "        movable_labels = movable_labels.view(-1).int()\n",
    "        mov_acc = movable_preds.eq(movable_labels).float()\n",
    "\n",
    "        gt_frame_R = labels[\"best_frame_R\"]\n",
    "        batch_size, _, num_frame_points = gt_frame_R.shape\n",
    "        pred_frame_R = preds[\"frame_R\"][:, :, :num_frame_points]\n",
    "        gt_frame_R = gt_frame_R.transpose(1, 2).contiguous().view(batch_size * num_frame_points, 3, 3)\n",
    "        gt_frame_R_inv = gt_frame_R.clone()\n",
    "        gt_frame_R_inv[:, :, 1:] = -gt_frame_R_inv[:, :, 1:]\n",
    "        pred_frame_R = pred_frame_R.transpose(1, 2).contiguous().view(batch_size * num_frame_points, 3, 3)\n",
    "        M = torch.bmm(gt_frame_R, pred_frame_R.transpose(1, 2))\n",
    "        angle = torch.acos(torch.clamp((M[:, 0, 0] + M[:, 1, 1] + M[:, 2, 2] - 1.0) / 2.0, -1.0, 1.0))\n",
    "        M_inv = torch.bmm(gt_frame_R_inv, pred_frame_R.transpose(1, 2))\n",
    "        angle_inv = torch.acos(torch.clamp((M_inv[:, 0, 0] + M_inv[:, 1, 1] + M_inv[:, 2, 2] - 1.0) / 2.0, -1.0, 1.0))\n",
    "\n",
    "        angle_min = torch.stack([angle, angle_inv], dim=1).min(1)[0]\n",
    "        gt_scene_score = labels[\"scene_score\"][:, :num_frame_points].contiguous().view(-1)\n",
    "        angle_min = (gt_scene_score * angle_min).mean()\n",
    "\n",
    "        gt_frame_t = labels[\"best_frame_t\"].view(-1)\n",
    "        pred_frame_t = preds[\"frame_t\"][:, :, :num_frame_points]\n",
    "        pred_frame_t = torch.argmax(pred_frame_t, dim=1).view(-1)\n",
    "        t_acc = pred_frame_t.eq(gt_frame_t).float()\n",
    "\n",
    "        # t_err = torch.mean(torch.sqrt(((gt_frame_t - pred_frame_t) ** 2).sum(1)))\n",
    "\n",
    "        return {\"cls_acc\": cls_acc,\n",
    "                \"mov_acc\": mov_acc,\n",
    "                \"R_err\": angle_min,\n",
    "                \"t_acc\": t_acc,\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399d751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_pointnet2_cls(cfg):\n",
    "def build_model(cfg):\n",
    "    net = PointNet2(\n",
    "        score_classes=cfg.DATA.SCORE_CLASSES,\n",
    "        num_centroids=cfg.MODEL.PN2.NUM_CENTROIDS,\n",
    "        radius=cfg.MODEL.PN2.RADIUS,\n",
    "        num_neighbours=cfg.MODEL.PN2.NUM_NEIGHBOURS,\n",
    "        sa_channels=cfg.MODEL.PN2.SA_CHANNELS,\n",
    "        fp_channels=cfg.MODEL.PN2.FP_CHANNELS,\n",
    "        num_fp_neighbours=cfg.MODEL.PN2.NUM_FP_NEIGHBOURS,\n",
    "        seg_channels=cfg.MODEL.PN2.SEG_CHANNELS,\n",
    "        num_removal_directions=cfg.DATA.NUM_REMOVAL_DIRECTIONS,\n",
    "        dropout_prob=cfg.MODEL.PN2.DROPOUT_PROB,\n",
    "    )\n",
    "\n",
    "    loss_func = PointNet2Loss(\n",
    "        label_smoothing=cfg.MODEL.PN2.LABEL_SMOOTHING,\n",
    "        neg_weight=cfg.MODEL.PN2.NEG_WEIGHT,\n",
    "    )\n",
    "    metric = PointNet2Metric()\n",
    "\n",
    "    return net, loss_func, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce5effa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading grasping labels...: 100%|██████████| 88/88 [00:30<00:00,  2.90it/s]\n",
      "Loading data path and collision labels...: 100%|██████████| 15/15 [00:02<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "root = '/home/po/TM5/graspnetAPI'\n",
    "valid_obj_idxs, grasp_labels = load_grasp_labels(root)\n",
    "train_dataset = GraspNetDataset(root, valid_obj_idxs, grasp_labels, split='train', remove_outlier=True, remove_invisible=True, num_points=20000)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9577ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grasp_list = train_dataset.__getitem__(0)['grasp_list']\n",
    "# point_clouds = train_dataset.__getitem__(0)['point_clouds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f796286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grasp_list.shape,point_clouds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d28849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "sys.path.append('/home/po/TM5/graspnet-baseline/pointnet2')\n",
    "\n",
    "from pytorch_utils import BNMomentumScheduler\n",
    "\n",
    "# Init datasets and dataloaders \n",
    "def my_worker_init_fn(worker_id):\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba4f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATALOADER = DataLoader(train_dataset, batch_size=1, shuffle=True,\n",
    "    num_workers=4, worker_init_fn=my_worker_init_fn, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "303fd1e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_dic = next(iter(TRAIN_DATALOADER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79e92bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['point_clouds', 'cloud_colors', 'xyz_label', 'q_label', 'score_label'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dic[\"point_clouds\"].permute(0,2,1).float().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd5858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposal_test.py\n",
    "import sys,os\n",
    "sys.path.append('/home/po/TM5/s4g-release/inference')\n",
    "import numpy as np\n",
    "import open3d\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from grasp_proposal.cloud_processor.cloud_processor import CloudPreProcessor\n",
    "from grasp_proposal.configs.yacs_config import load_cfg_from_file\n",
    "# from grasp_proposal.network_models.models.build_model import build_model\n",
    "from grasp_proposal.utils.checkpoint import CheckPointer\n",
    "from grasp_proposal.utils.file_logger_cls import loggin_to_file\n",
    "from grasp_proposal.utils.grasp_visualizer import GraspVisualizer\n",
    "from grasp_proposal.utils.logger import setup_logger, MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e27fcb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-30 14:46:09,214 S4G INFO: Using 2 of GPUs\n",
      "2021-11-30 14:46:09,215 S4G INFO: Load config file from /home/po/TM5/s4g-release/inference/grasp_proposal/configs/curvature_model.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PointNet2Loss(\n",
       "  (loss1): L1Loss()\n",
       "  (loss2): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proposal_test.py\n",
    "# load_static batch data\n",
    "# \n",
    "cfg_path = \"/home/po/TM5/s4g-release/inference/grasp_proposal/configs/curvature_model.yaml\"\n",
    "cfg = load_cfg_from_file(cfg_path)\n",
    "cfg.defrost()\n",
    "# cfg.TEST.WEIGHT = cfg.TEST.WEIGHT.replace(\"${PROJECT_HOME}\", os.path.join(os.getcwd(), \"../\"))\n",
    "# cfg.TEST.WEIGHT = '/home/po/TM5/s4g-release/inference/trained_models/curvature_model.pth'\n",
    "cfg.TEST.WEIGHT = cfg.TEST.WEIGHT.replace(\"${PROJECT_HOME}\", os.path.join('/home/po/TM5/s4g-release/inference'))\n",
    "cfg.freeze()\n",
    "assert cfg.TEST.BATCH_SIZE == 1\n",
    "\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "logger = setup_logger(\"S4G\", output_dir, \"unit_test\")\n",
    "logger.info(\"Using {} of GPUs\".format(torch.cuda.device_count()))\n",
    "logger.info(\"Load config file from {}\".format(cfg_path))\n",
    "logger.debug(\"Running with config \\n {}\".format(cfg))\n",
    "\n",
    "model, loss_func, _ = build_model(cfg)\n",
    "loss_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecfe608",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = {'a':1,'b':1,'c':1}\n",
    "\n",
    "sum(loss.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57afa3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay_steps = '8,12,16'\n",
    "lr_decay_rates = '0.1,0.1,0.1'\n",
    "EPOCH_CNT = 0\n",
    "LR_DECAY_STEPS = [int(x) for x in lr_decay_steps.split(',')]\n",
    "LR_DECAY_RATES = [float(x) for x in lr_decay_rates.split(',')]\n",
    "assert(len(LR_DECAY_STEPS)==len(LR_DECAY_RATES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab1dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    adjust_learning_rate(optimizer, EPOCH_CNT)\n",
    "    bnm_scheduler.step() # decay BN momentum\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    for batch_idx, batch_data_label in enumerate(tqdm(TRAIN_DATALOADER)):\n",
    "        data_batch = {\n",
    "        \"point_clouds\": batch_data_label[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "        \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"q_label\": batch_data_label[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "        }\n",
    "        predictions = model(data_batch)\n",
    "    #     print(batch_idx)\n",
    "    #     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "    #     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "        loss = loss_func(predictions, data_batch)\n",
    "        sum(loss.values()).backward()   \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss\n",
    "def evaluate_one_epoch():\n",
    "    model.train()\n",
    "    for batch_idx, batch_data_label in enumerate(TRAIN_DATALOADER):\n",
    "        data_batch = {\n",
    "        \"point_clouds\": batch_data_label[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "        \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"q_label\": batch_data_label[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            predictions = model(data_batch)\n",
    "    #     print(batch_idx)\n",
    "    #     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "    #     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "        loss = loss_func(predictions, data_batch)\n",
    "        sum(loss.values())\n",
    "        \n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33d3a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** EPOCH 000 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.500000\n",
      "2021-11-30 14:53:12.722039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:31<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'score_loss': tensor(0.0162, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2579, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 001 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.500000\n",
      "2021-11-30 15:27:44.309269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:28<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'score_loss': tensor(0.0130, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2556, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 002 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.500000\n",
      "2021-11-30 16:02:12.646190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:21<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {'score_loss': tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2537, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 003 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.250000\n",
      "2021-11-30 16:36:34.374705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:21<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 {'score_loss': tensor(0.0131, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2548, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 004 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.250000\n",
      "2021-11-30 17:10:55.932605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:20<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 {'score_loss': tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2548, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 005 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.125000\n",
      "2021-11-30 17:45:16.220732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:19<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 {'score_loss': tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2556, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 006 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.125000\n",
      "2021-11-30 18:19:36.149373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:21<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 {'score_loss': tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2524, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 007 ****\n",
      "Current learning rate: 0.001000\n",
      "Current BN decay momentum: 0.062500\n",
      "2021-11-30 18:53:57.394852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:20<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 {'score_loss': tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2557, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 008 ****\n",
      "Current learning rate: 0.000100\n",
      "Current BN decay momentum: 0.062500\n",
      "2021-11-30 19:28:18.121216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:21<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 {'score_loss': tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2553, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "**** EPOCH 009 ****\n",
      "Current learning rate: 0.000100\n",
      "Current BN decay momentum: 0.031250\n",
      "2021-11-30 20:02:39.187106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3840/3840 [34:20<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 {'score_loss': tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>), 'q_loss': tensor(0.2554, device='cuda:0', grad_fn=<L1LossBackward0>), 'xyz_loss': tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "learning_rate = 0.001\n",
    "def get_current_lr(epoch):\n",
    "    lr = learning_rate\n",
    "    for i,lr_decay_epoch in enumerate(LR_DECAY_STEPS):\n",
    "        if epoch >= lr_decay_epoch:\n",
    "            lr *= LR_DECAY_RATES[i]\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "LOG_FOUT = open(os.path.join('/home/po/TM5/s4g-release/inference/grasp_proposal/network_models/models', 'log_train.txt'), 'a')\n",
    "\n",
    "def log_string(out_str):\n",
    "    LOG_FOUT.write(out_str+'\\n')\n",
    "    LOG_FOUT.flush()\n",
    "    print(out_str)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "bn_decay_step = 2\n",
    "bn_decay_rate = 0.5\n",
    "start_epoch = 0\n",
    "BN_MOMENTUM_INIT = 0.5\n",
    "BN_MOMENTUM_MAX = 0.001\n",
    "bn_lbmd = lambda it: max(BN_MOMENTUM_INIT * bn_decay_rate**(int(it / bn_decay_step)), BN_MOMENTUM_MAX)\n",
    "bnm_scheduler = BNMomentumScheduler(model, bn_lambda=bn_lbmd, last_epoch=start_epoch-1)\n",
    "\n",
    "min_loss = 1e10\n",
    "loss = 0\n",
    "global EPOCH_CNT\n",
    "trained_model_path = output_dir\n",
    "check_pointer = CheckPointer(model, save_dir=trained_model_path, logger=logger)\n",
    "for epoch in range(10):\n",
    "    EPOCH_CNT = epoch\n",
    "    log_string('**** EPOCH %03d ****' % (epoch))\n",
    "    log_string('Current learning rate: %f'%(get_current_lr(epoch)))\n",
    "    log_string('Current BN decay momentum: %f'%(bnm_scheduler.lmbd(bnm_scheduler.last_epoch)))\n",
    "    log_string(str(datetime.now()))\n",
    "    # Reset numpy seed.\n",
    "    # REF: https://github.com/pytorch/pytorch/issues/5059\n",
    "    np.random.seed()\n",
    "    loss = train_one_epoch()\n",
    "    print(epoch,loss)\n",
    "#     loss = evaluate_one_epoch()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6c00557",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'graspv1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f393ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_state_dict(torch.load('graspv1.pth'))\n",
    "model, _, _ = build_model(cfg)\n",
    "if torch.cuda.device_count() > 13:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "model.load_state_dict(torch.load('graspv1.pth'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data_batch = {\n",
    "        \"point_clouds\": tmp_dic[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "        \"xyz_label\": tmp_dic[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"q_label\": tmp_dic[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "        \"score_label\": tmp_dic[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "        }\n",
    "#     tac = time.time()\n",
    "#     data_time = tac - tic\n",
    "    predictions = model(data_batch)\n",
    "#     tic = time.time()\n",
    "#     batch_time = tic - tac\n",
    "#     with open(\"inference_time_{}.txt\".format(\"ours\"), \"a+\") as f:\n",
    "#         f.write(\"{:.4f}\\n\".format(batch_time * 1000.0))\n",
    "#     meters.update(time=batch_time, data=data_time)\n",
    "\n",
    "#     logger.info(meters.delimiter.join([\"{meters}\", ]).format(meters=str(meters), ))\n",
    "\n",
    "#     top_poses, score = loggin_to_file(data_batch, predictions, 0, output_dir, prefix=\"test\", with_label=False)\n",
    "#     visualizer = GraspVisualizer(pcd)\n",
    "#     visualizer.add_multiple_poses(top_poses)\n",
    "#     visualizer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grasp_scene(data_batch,predictions):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d8fbc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 3]) torch.Size([20000, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tmp_dic['point_clouds'].squeeze(0).shape,tmp_dic['cloud_colors'].squeeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc13b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test open3d \n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ab507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gripper_pro_max(center, R, width, depth, score=1, color=None):\n",
    "    '''\n",
    "    Author: chenxi-wang\n",
    "    \n",
    "    **Input:**\n",
    "\n",
    "    - center: numpy array of (3,), target point as gripper center\n",
    "\n",
    "    - R: numpy array of (3,3), rotation matrix of gripper\n",
    "\n",
    "    - width: float, gripper width\n",
    "\n",
    "    - score: float, grasp quality score\n",
    "\n",
    "    **Output:**\n",
    "\n",
    "    - open3d.geometry.TriangleMesh\n",
    "    '''\n",
    "    x, y, z = center\n",
    "    height=0.004\n",
    "    finger_width = 0.004\n",
    "    tail_length = 0.04\n",
    "    depth_base = 0.02\n",
    "    \n",
    "    if color is not None:\n",
    "        color_r, color_g, color_b = color\n",
    "    else:\n",
    "        color_r = score # red for high score\n",
    "        color_g = 0\n",
    "        color_b = 1 - score # blue for low score\n",
    "    \n",
    "    left = create_mesh_box(depth+depth_base+finger_width, finger_width, height)\n",
    "    right = create_mesh_box(depth+depth_base+finger_width, finger_width, height)\n",
    "    bottom = create_mesh_box(finger_width, width, height)\n",
    "    tail = create_mesh_box(tail_length, finger_width, height)\n",
    "\n",
    "    left_points = np.array(left.vertices)\n",
    "    left_triangles = np.array(left.triangles)\n",
    "    left_points[:,0] -= depth_base + finger_width\n",
    "    left_points[:,1] -= width/2 + finger_width\n",
    "    left_points[:,2] -= height/2\n",
    "\n",
    "    right_points = np.array(right.vertices)\n",
    "    right_triangles = np.array(right.triangles) + 8\n",
    "    right_points[:,0] -= depth_base + finger_width\n",
    "    right_points[:,1] += width/2\n",
    "    right_points[:,2] -= height/2\n",
    "\n",
    "    bottom_points = np.array(bottom.vertices)\n",
    "    bottom_triangles = np.array(bottom.triangles) + 16\n",
    "    bottom_points[:,0] -= finger_width + depth_base\n",
    "    bottom_points[:,1] -= width/2\n",
    "    bottom_points[:,2] -= height/2\n",
    "\n",
    "    tail_points = np.array(tail.vertices)\n",
    "    tail_triangles = np.array(tail.triangles) + 24\n",
    "    tail_points[:,0] -= tail_length + finger_width + depth_base\n",
    "    tail_points[:,1] -= finger_width / 2\n",
    "    tail_points[:,2] -= height/2\n",
    "\n",
    "    vertices = np.concatenate([left_points, right_points, bottom_points, tail_points], axis=0)\n",
    "    vertices = np.dot(R, vertices.T).T + center\n",
    "    triangles = np.concatenate([left_triangles, right_triangles, bottom_triangles, tail_triangles], axis=0)\n",
    "    colors = np.array([ [color_r,color_g,color_b] for _ in range(len(vertices))])\n",
    "\n",
    "    gripper = o3d.geometry.TriangleMesh()\n",
    "    gripper.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "    gripper.triangles = o3d.utility.Vector3iVector(triangles)\n",
    "    gripper.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "    return gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61c9aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspnetAPI import GraspNet, Grasp, GraspGroup\n",
    "\n",
    "g = Grasp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56257a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_pcd = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "# axis_pcd_tx = copy.deepcopy(axis_pcd).translate((1.3,0,0))\n",
    "# points = np.array([[0.1, 0.1, 0.1], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "# colors = [[1, 1, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "points = tmp_dic['point_clouds'].squeeze(0)\n",
    "colors = tmp_dic['cloud_colors'].squeeze(0)\n",
    "test_pcd = open3d.geometry.PointCloud()  # 定义点云\n",
    "geometries = [axis_pcd,test_pcd,g.to_open3d_geometry()]\n",
    "# geometries.append(axis_pcd)\n",
    "test_pcd.points = o3d.utility.Vector3dVector(points)  # 定义点云坐标位置\n",
    "test_pcd.colors = o3d.utility.Vector3dVector(colors)  # 定义点云的颜色\n",
    "\n",
    "open3d.visualization.draw_geometries(geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c011434",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "model.train()\n",
    "\n",
    "for batch_idx, batch_data_label in enumerate(TRAIN_DATALOADER):\n",
    "    data_batch = {\n",
    "    \"point_clouds\": batch_data_label[\"point_clouds\"].permute(0,2,1).float().cuda(),\n",
    "    \"xyz_label\": batch_data_label[\"xyz_label\"].permute(0,2,1).float().cuda(),\n",
    "    \"q_label\": batch_data_label[\"q_label\"].permute(0,2,1).float().cuda(),\n",
    "    \"score_label\": batch_data_label[\"score_label\"].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "    }\n",
    "    predictions = model(data_batch)\n",
    "    print(batch_idx)\n",
    "#     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "#     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "    loss = loss_func(predictions, data_batch)\n",
    "    sum(loss.values()).backward()   \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "#     model.save\n",
    "#     print(loss['xyz_loss'],loss['q_loss'],loss['score_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269917cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss(predictions, data_batch1)\n",
    "loss_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a54933",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 10:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "elif torch.cuda.device_count() == 2:\n",
    "    model = model.cuda()\n",
    "    \n",
    "model.eval()\n",
    "data_batch = {\n",
    "\"point_clouds\": tmp_dic['point_clouds'].permute(0,2,1).float().cuda(),\n",
    "\"xyz_label\": tmp_dic['xyz_label'].permute(0,2,1).float().cuda(),\n",
    "\"q_label\": tmp_dic['q_label'].permute(0,2,1).float().cuda(),\n",
    "\"score_label\": tmp_dic['score_label'].permute(0,2,1).unsqueeze(-1).float().cuda(),\n",
    "}\n",
    "predictions = model(data_batch)\n",
    "# print(batch_idx)\n",
    "#     print('pred',predictions['xyz_pred'].shape,predictions['q_pred'].shape,predictions['score_pred'].shape)\n",
    "#     print('dlabel',data_batch['point_clouds'].shape,data_batch['xyz_label'].shape,data_batch['q_label'].shape,data_batch['score_label'].shape)\n",
    "loss = loss(predictions, data_batch)\n",
    "# sum(loss.values()).backward()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252287d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_dic['point_clouds'].shape,tmp_dic['xyz_label'].shape,tmp_dic['q_label'].shape,tmp_dic['score_label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cad47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.keys())\n",
    "print(predictions['score_pred'].shape,predictions['q_pred'].shape,predictions['xyz_pred'].shape)\n",
    "print(data_batch['score_label'].shape,data_batch['q_label'].permute(0,2,1).shape,data_batch['xyz_label'].permute(0,2,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = torch.tensor([[[2., 2., 2.],\n",
    "#          [3., 3., 3.]],\n",
    "\n",
    "#         [[4., 4., 4.],\n",
    "#          [5., 5., 6.]]])\n",
    "# B = torch.tensor([[[1., 1., 1.],\n",
    "#          [1., 1., 1.]],\n",
    "\n",
    "#         [[1., 1., 1.],\n",
    "#          [1., 1., 1.]]])\n",
    "A = torch.ones(1,4,20000)\n",
    "B = torch.ones(1,4,20000)\n",
    "D = (A -B)**2\n",
    "E = ((A -B)**2).mean(1,True)\n",
    "print(D.shape,E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db58edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_label = data_batch[\"q_label\"].permute(0,2,1)#(1,4,20)\n",
    "q_pred = predictions[\"q_pred\"]\n",
    "q_loss = ((q_pred - q_label) ** 2).mean(1, True)\n",
    "\n",
    "q_loss.shape\n",
    "# # weight loss according to gt_score\n",
    "# score_label = labels[\"score_label\"].permute(0,2,1).unsqueeze(-1)\n",
    "# score_pred = preds[\"score_pred\"]\n",
    "# score_loss = ((score_pred - score_label) ** 2).mean(1, True)\n",
    "\n",
    "\n",
    "# xyz_label = labels[\"xyz_label\"].permute(0,2,1)\n",
    "# xyz_pred = preds[\"xyz_pred\"]\n",
    "# xyz_loss = ((xyz_pred - xyz_label) ** 2).mean(1, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb73f820",
   "metadata": {},
   "source": [
    "q_label = q_label.permute(0,2,1)\n",
    "q_label.shape\n",
    "xyz_label.permute(0,2,1).shape\n",
    "score_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4698a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions['score_pred'].shape,predictions['q_pred'].shape,predictions['xyz_pred'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cebc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn2_loss_fn = loss().cuda()\n",
    "loss = pn2_loss_fn(predictions, data_batch)\n",
    "loss['xyz_loss'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a65541",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac5fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/po/TM5/s4g-release/inference')\n",
    "import numpy as np\n",
    "import open3d\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from grasp_proposal.cloud_processor.cloud_processor import CloudPreProcessor\n",
    "from grasp_proposal.configs.yacs_config import load_cfg_from_file\n",
    "from grasp_proposal.network_models.models.build_model import build_model\n",
    "from grasp_proposal.utils.checkpoint import CheckPointer\n",
    "from grasp_proposal.utils.file_logger_cls import loggin_to_file\n",
    "from grasp_proposal.utils.grasp_visualizer import GraspVisualizer\n",
    "from grasp_proposal.utils.logger import setup_logger, MetricLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_training_data = np.load(\"/home/po/TM5/s4g-release/2638_view_0.p\", allow_pickle=True)\n",
    "# cloud_array = single_training_data[\"point_cloud\"]\n",
    "# cloud = CloudPreProcessor(open3d.geometry.PointCloud(open3d.utility.Vector3dVector(cloud_array.T)), False)\n",
    "# # do not filter workspace here since training data\n",
    "# cloud.voxelize()\n",
    "# cloud.remove_outliers()\n",
    "# points = np.asarray(cloud.pcd.points)\n",
    "# if points.shape[0] > 25600:\n",
    "#     random_index = np.random.choice(np.arange(points.shape[0]), 25600, replace=False)\n",
    "# else:\n",
    "#     random_index = np.random.choice(np.arange(points.shape[0]), 25600, replace=True)\n",
    "\n",
    "# points = points[random_index, :]\n",
    "# C = torch.tensor(points, dtype=torch.float32).unsqueeze(0).transpose(1, 2)\n",
    "# B = torch.tensor(points, dtype=torch.float32).unsqueeze(0)\n",
    "# A = torch.tensor(points, dtype=torch.float32)\n",
    "# # data_batch = {\"scene_points\": torch.tensor(points, dtype=torch.float32).unsqueeze(0).transpose(1, 2)}\n",
    "# # print(data_batch,cloud.pcd)\n",
    "# print(A.shape,B.shape,C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_training_data['point_cloud'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d344af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = torch.ones(1, 9, 25600) \n",
    "t = torch.ones(1, 3, 25600)\n",
    "local_search_frame = torch.cat([R, t], dim=1).unsqueeze(-1)\n",
    "local_search_frame = local_search_frame.repeat(1, 4, 1, 1)\n",
    "# sparse_feature = sparse_feature.unsqueeze(-1)\n",
    "# valid_feature = torch.cat([sparse_feature, local_search_frame], dim=1)\n",
    "# local_search_logit = self.grasp_eval_logit(self.mlp_grasp_eval(valid_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44881ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search_frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd24ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
